{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting training Data Face-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-2-93c54271aaf6>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if facesA is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples For MODEL-1 Completed\n"
     ]
    }
   ],
   "source": [
    "A_classifier=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "# Load functions\n",
    "def faceA_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    facesA = A_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if facesA is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in facesA:\n",
    "        cropped_faceA = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_faceA\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if faceA_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        faceA = cv2.resize(faceA_extractor(frame), (200, 200))\n",
    "        faceA = cv2.cvtColor(faceA, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = '/Faces_A/A' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, faceA)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(faceA, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', faceA)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples For MODEL-1 Completed\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting training Data Face-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-3-84572d69baf3>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if facesB is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples For MODEL-2 Completed\n"
     ]
    }
   ],
   "source": [
    "B_classifier=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "# Load functions\n",
    "def faceB_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    facesB = B_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if facesB is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in facesB:\n",
    "        cropped_faceB = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_faceB\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if faceB_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        faceB = cv2.resize(faceB_extractor(frame), (200, 200))\n",
    "        faceB = cv2.cvtColor(faceB, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = '/Faces_A/B' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, faceB)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(faceB, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', faceB)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples For MODEL-2 Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training for FACE-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-1 trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "\n",
    "data_path = 'Faces_A/A/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]     \n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "     image_path = data_path + onlyfiles[i]\n",
    "     images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "     Training_Data.append(np.asarray(images, dtype=np.int8))\n",
    "     Labels.append(i)\n",
    "\n",
    "\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "a_model  = cv2.face.LBPHFaceRecognizer_create() \n",
    "a_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model-1 trained sucessefully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training For Face-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-2 trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "data_path = 'Faces_B/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]        #function to read all of images from data_path line by line\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Label = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Label.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Label = np.asarray(Label, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "b_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "b_model.train(np.asarray(Training_Data), np.asarray(Label))\n",
    "print(\"Model-2 trained sucessefully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION FOR MULTI-FACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-7-09d9bb507b57>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "send successfully....\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "A_classifier=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = A_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "        return img, roi                                             #region of interest(roi)\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        results = a_model.predict(face)\n",
    "       \n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is vimal'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 60:\n",
    "            cv2.putText(image, \"Hey vimal sir\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            #Auto()\n",
    "            dete=True\n",
    "            print(\"done\")\n",
    "   \n",
    "        else:\n",
    "            \n",
    "            cv2.putText(image, \"I dont know, who r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if dete==True:\n",
    "    #send email\n",
    "    import smtplib as s\n",
    "    from email.mime.text import MIMEText\n",
    "    from email.mime.image import MIMEImage\n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    from email import encoders\n",
    "            \n",
    "    sender= \"piyush007panchariya@gmail.com\"\n",
    "    receiver=\"piyushpanchariya2001@gmail.com\"\n",
    "    password=\"pyxjryuydwmblyca\"\n",
    "    subject=\"Someone Just Checked In\"\n",
    "    email_body=\"<h1>ALL GOOD....Its me *Vimal*</h1>\"\n",
    "    \n",
    "    message= MIMEMultipart()\n",
    "    message['From']=sender\n",
    "    message['To']=receiver\n",
    "    message['Subject'] =subject\n",
    "    message.attach(MIMEText(email_body, 'html'))\n",
    "    \n",
    "    server=s.SMTP('smtp.gmail.com',587)\n",
    "    server.starttls()\n",
    "    server.login(sender,password)\n",
    "    text = message.as_string()\n",
    "    server.sendmail(sender, receiver, text)\n",
    "  \n",
    "    print('send successfully....')\n",
    "    server.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-8-0a31c043d12e>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces2 is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instances created\n",
      "i-0b9767a85c408ae78\n",
      "EBS created\n",
      "vol-037a6e1969adb41c5\n",
      "EC2 EBS Attached\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "B_classifier=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def face_detectorB(img2, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    faces2 = B_classifier.detectMultiScale(gray2, 1.3, 5)\n",
    "    if faces2 is ():\n",
    "        return img2, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces2:\n",
    "        \n",
    "        cv2.rectangle(img2,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi2 = img2[y:y+h, x:x+w]\n",
    "        roi2 = cv2.resize(roi2, (200, 200))\n",
    "    return img2, roi2                                             #region of interest(roi)\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    image2 , face2 = face_detectorB(frame2)\n",
    "    \n",
    "    try:\n",
    "        face2 = cv2.cvtColor(face2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "       \n",
    "        results2 = b_model.predict(face2)\n",
    "        \n",
    "        if results2[1] < 500:\n",
    "            confidence2 = int( 100 * (1 - (results2[1])/400) )\n",
    "            display_string = str(confidence2) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image2, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        \n",
    "        if confidence2 > 80:\n",
    "            cv2.putText(image2, \"Hey Abhinav....Lauching AWS services\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image2 )\n",
    "            \n",
    "            dete=True\n",
    "            \n",
    "            \n",
    "\n",
    "         \n",
    "        else:\n",
    "            \n",
    "            cv2.putText(image2, \"I dont know, who r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image2, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image2, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image2 )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#i used  BOTO3 for accessing my aws services , for this you have to install module and also you have to login using aws cli ('aws configure') previously.\n",
    "\n",
    "if dete==True:\n",
    "    import boto3\n",
    "    import time\n",
    "    ec2_resource=boto3.resource(\"ec2\")\n",
    "    instances = ec2_resource.create_instances(ImageId='ami-0ad704c126371a549', InstanceType='t2.micro',MaxCount=1,MinCount=1)\n",
    "    inst = instances[0]\n",
    "    imgid=inst.id\n",
    "    print('instances created')\n",
    "    print(imgid)\n",
    "    ec2_client=boto3.client(\"ec2\")\n",
    "    vol = ec2_client.create_volume(AvailabilityZone='ap-south-1a',Size=5,VolumeType='gp2',TagSpecifications=[{'ResourceType': 'volume','Tags': [{'Key': 'Name','Value': 'TASK6'},]},],)\n",
    "    Volid = vol['VolumeId']\n",
    "    print('EBS created')\n",
    "    print(Volid)\n",
    "    \n",
    "    time.sleep(40)     #because it takes time to initialize above 2 services \n",
    "   \n",
    "    ec2_client.attach_volume(Device='/dev/sdf', InstanceId= imgid, VolumeId= Volid)\n",
    "    \n",
    "    print('EC2 EBS Attached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
